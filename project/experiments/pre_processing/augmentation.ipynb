{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98824deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# תא ניסוי: augmentation + oversampling for minority class (cats)\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from torchvision import transforms\n",
    "import random\n",
    "\n",
    "from dataset import load_imbalanced_cifar\n",
    "from model import SimpleCNN\n",
    "from pipeline.train import train_model\n",
    "from pipeline.eval import eval_model\n",
    "from utils import get_device, set_seed, plot_cm\n",
    "from experiment_logger import log_experiment_to_sheet\n",
    "\n",
    "# ==== SETUP ====\n",
    "set_seed(42)\n",
    "device = get_device()\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# ==== DEFINE AUGMENTATION (same as before) ====\n",
    "\n",
    "cat_aug = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(20),\n",
    "        transforms.ColorJitter(brightness=0.3, contrast=0.3),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "class AugmentedCIFAR(Dataset):\n",
    "    \"\"\"Wrap base dataset; for augmented indices, apply augmentation every time.\"\"\"\n",
    "\n",
    "    def __init__(self, base_dataset, indices, augment_label=0, transform=None):\n",
    "        self.base = base_dataset\n",
    "        self.indices = indices\n",
    "        self.augment_label = augment_label\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        real_idx = self.indices[idx]\n",
    "        img, label = self.base[real_idx]\n",
    "\n",
    "        # augmentation is applied only to minority label\n",
    "        if label == self.augment_label and self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label\n",
    "\n",
    "\n",
    "# ==== LOAD ORIGINAL DATA ====\n",
    "base_dataset = load_imbalanced_cifar(cat_count=30, dog_count=500)\n",
    "print(\"Loaded base dataset (30 cats / 500 dogs)\")\n",
    "\n",
    "# ==== GET INDICES ====\n",
    "cat_indices = [i for i, (_, y) in enumerate(base_dataset) if y == 0]\n",
    "dog_indices = [i for i, (_, y) in enumerate(base_dataset) if y == 1]\n",
    "\n",
    "# ==== TRAIN/TEST SPLIT ====\n",
    "random.shuffle(cat_indices)\n",
    "random.shuffle(dog_indices)\n",
    "\n",
    "cat_train = cat_indices[: int(0.8 * len(cat_indices))]\n",
    "cat_test = cat_indices[int(0.8 * len(cat_indices)) :]\n",
    "\n",
    "dog_train = dog_indices[: int(0.8 * len(dog_indices))]\n",
    "dog_test = dog_indices[int(0.8 * len(dog_indices)) :]\n",
    "\n",
    "# ==== OVERSAMPLING: make cats ≈ dogs ====\n",
    "target = len(dog_train)  # number of dogs in train\n",
    "repeat_factor = target // len(cat_train)\n",
    "remainder = target % len(cat_train)\n",
    "\n",
    "oversampled_cats = cat_train * repeat_factor + cat_train[:remainder]\n",
    "\n",
    "balanced_train_indices = oversampled_cats + dog_train\n",
    "random.shuffle(balanced_train_indices)\n",
    "\n",
    "print(f\"Train cats: {len(oversampled_cats)}, Train dogs: {len(dog_train)}\")\n",
    "print(f\"Balanced train size: {len(balanced_train_indices)}\")\n",
    "\n",
    "# ==== BUILD DATASETS ====\n",
    "train_ds = AugmentedCIFAR(\n",
    "    base_dataset, balanced_train_indices, augment_label=0, transform=cat_aug\n",
    ")\n",
    "\n",
    "test_ds = Subset(base_dataset, cat_test + dog_test)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=32, shuffle=False)\n",
    "\n",
    "print(\"Final train size:\", len(train_ds))\n",
    "print(\"Final test size:\", len(test_ds))\n",
    "\n",
    "# ==== MODEL & TRAINING ====\n",
    "model = SimpleCNN().to(device)\n",
    "\n",
    "model, losses = train_model(\n",
    "    model=model, train_loader=train_loader, device=device, epochs=5\n",
    ")\n",
    "\n",
    "# ==== EVALUATION ====\n",
    "overall, cat_acc, dog_acc, cm = eval_model(model, test_loader, device)\n",
    "\n",
    "print(\"==== Evaluation with Balanced Augmentation ====\")\n",
    "print(\"Overall accuracy:\", overall)\n",
    "print(\"Cat accuracy:\", cat_acc)\n",
    "print(\"Dog accuracy:\", dog_acc)\n",
    "\n",
    "plot_cm(cm)\n",
    "\n",
    "# ==== LOG TO GOOGLE SHEETS ====\n",
    "metrics = {\n",
    "    \"overall_acc\": overall,\n",
    "    \"cat_acc\": cat_acc,\n",
    "    \"dog_acc\": dog_acc,\n",
    "}\n",
    "\n",
    "config = {\n",
    "    \"method\": \"augmentation_balanced\",\n",
    "    \"epochs\": 5,\n",
    "    \"batch_size\": 32,\n",
    "    \"lr\": 1e-3,\n",
    "    \"cats_original\": len(cat_indices),\n",
    "    \"dogs_original\": len(dog_indices),\n",
    "    \"cats_after_oversample\": len(oversampled_cats),\n",
    "}\n",
    "\n",
    "log_experiment_to_sheet(\n",
    "    experiment_name=\"augmentation\",\n",
    "    metrics=metrics,\n",
    "    config=config,\n",
    "    notes=\"Balanced augmentation: oversampling + transforms\",\n",
    ")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
